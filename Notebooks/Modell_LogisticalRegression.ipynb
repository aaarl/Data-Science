{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Random Forest"]},{"cell_type":"code","execution_count":55,"metadata":{},"outputs":[],"source":["from pyspark.sql.types import BooleanType\n","from pyspark.ml.feature import IndexToString, Normalizer, StringIndexer, VectorAssembler, VectorIndexer\n","from pyspark.ml.classification import RandomForestClassifier, LinearSVC, OneVsRest, LogisticRegression\n","from pyspark.sql.session import SparkSession\n","from pyspark.sql.functions import expr\n","from pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator\n","from helpers.helper_functions import translate_to_file_string\n","from pyspark.ml.classification import DecisionTreeClassifier\n","from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n","from pyspark.ml import Pipeline\n","from pyspark.mllib.evaluation import MulticlassMetrics\n","from pyspark.ml.classification import RandomForestClassifier\n","from pyspark.mllib.classification import LogisticRegressionWithLBFGS\n","from pyspark.mllib.util import MLUtils\n","from pyspark.mllib.evaluation import MulticlassMetrics\n","from pyspark.ml.regression import LinearRegression\n","\n","\n","import pandas as pd\n","from IPython.display import display, HTML\n","import matplotlib.pyplot as plt\n","from pandas.plotting import scatter_matrix\n","\n","#Change Column Names\n","def delete_space(df):\n","    names = df.schema.names\n","    for name in names:\n","        newName = name.replace(\" \",\"\")\n","        df = df.withColumnRenamed(name, newName)\n","    return df"]},{"cell_type":"code","execution_count":56,"metadata":{},"outputs":[],"source":["inputFile = translate_to_file_string(\"../data/data.csv\")"]},{"cell_type":"markdown","metadata":{},"source":["Spark session creation "]},{"cell_type":"code","execution_count":57,"metadata":{},"outputs":[],"source":["spark = (SparkSession\n","       .builder\n","       .appName(\"Modell_randomForest\")\n","       .getOrCreate())"]},{"cell_type":"markdown","metadata":{},"source":["DataFrame creation using an ifered Schema "]},{"cell_type":"code","execution_count":146,"metadata":{},"outputs":[],"source":["# create a DataFrame using an ifered Schema \n","df = spark.read.option(\"header\", \"true\") \\\n","       .option(\"inferSchema\", \"true\") \\\n","       .option(\"delimiter\", \";\") \\\n","       .csv(inputFile) "]},{"cell_type":"markdown","metadata":{},"source":["Prepare training and test data."]},{"cell_type":"code","execution_count":147,"metadata":{},"outputs":[{"output_type":"stream","name":"stdout","text":["root\n |-- CustomerID: string (nullable = true)\n |-- Gender: string (nullable = true)\n |-- SeniorCitizen: integer (nullable = true)\n |-- Partner: string (nullable = true)\n |-- Dependents: string (nullable = true)\n |-- Tenure: integer (nullable = true)\n |-- PhoneService: string (nullable = true)\n |-- MultipleLines: string (nullable = true)\n |-- InternetService: string (nullable = true)\n |-- OnlineSecurity: string (nullable = true)\n |-- OnlineBackup: string (nullable = true)\n |-- DeviceProtection: string (nullable = true)\n |-- TechSupport: string (nullable = true)\n |-- StreamingTV: string (nullable = true)\n |-- StreamingMovies: string (nullable = true)\n |-- Contract: string (nullable = true)\n |-- PaperlessBilling: string (nullable = true)\n |-- PaymentMethod: string (nullable = true)\n |-- MonthlyCharges: double (nullable = true)\n |-- TotalCharges: double (nullable = true)\n\n"]}],"source":["df = delete_space(df)\n","df.printSchema()\n","\n","# #Create Pandas DataFrame\n","# df_pandas = df.toPandas()\n","# pandasCol = list(df_pandas)\n","# for col in pandasCol:\n","#     if df_pandas[col].dtypes=='object':\n","#         #ToInteger\n","#         df_pandas[col]= pd.factorize(df_pandas[col])[0]\n","\n","\n","\n","# newCols = []\n","# for col in pandasCol:\n","#     if not col == \"Tenure\" and not col == \"MonthlyCharges\" and not col == \"TotalCharges\" and not col == \"Contract\":\n","#         newCols.append(col)\n","\n","# df_pandas[newCols]=(df_pandas[newCols]-df_pandas[newCols].min())/(df_pandas[newCols].max()-df_pandas[newCols].min())\n","# df_pandas.info()\n","\n","# HTML(df_pandas.head(5).to_html())\n","\n","# df2 = spark.createDataFrame(df_pandas)\n","\n","# featureCols = df2.columns.copy()\n","# featureCols.remove(\"CustomerID\")\n","# featureCols.remove(\"Contract\")\n","# print(featureCols)\n","\n","# assembler =  VectorAssembler(outputCol=\"features\", inputCols=featureCols)\n","\n","# #Keep Nullvalues \n","# assembler.setHandleInvalid(\"keep\")"]},{"cell_type":"code","execution_count":148,"metadata":{},"outputs":[],"source":["df = df.where(\"TotalCharges IS NOT NULL\")"]},{"cell_type":"code","execution_count":149,"metadata":{},"outputs":[],"source":["IDIndexer = StringIndexer().setInputCol(\"CustomerID\").setOutputCol(\"CustomerID_Int\").fit(df)\n","genderIndexer = StringIndexer().setInputCol(\"Gender\").setOutputCol(\"Gender_Int\").fit(df)\n","seniorIndexer = StringIndexer().setInputCol(\"SeniorCitizen\").setOutputCol(\"SeniorCitizen_Int\").fit(df)\n","partnerIndexer = StringIndexer().setInputCol(\"Partner\").setOutputCol(\"Partner_Int\").fit(df)\n","DependentsIndexer = StringIndexer().setInputCol(\"Dependents\").setOutputCol(\"Dependents_Int\").fit(df)\n","tenureIndexer = StringIndexer().setInputCol(\"Tenure\").setOutputCol(\"Tenure_Int\").fit(df)\n","phoneIndexer = StringIndexer().setInputCol(\"PhoneService\").setOutputCol(\"PhoneService_Int\").fit(df)\n","multipleIndexer = StringIndexer().setInputCol(\"MultipleLines\").setOutputCol(\"MultipleLines_Int\").fit(df)\n","internetIndexer = StringIndexer().setInputCol(\"InternetService\").setOutputCol(\"InternetService_Int\").fit(df)\n","onlineSecurityIndexer = StringIndexer().setInputCol(\"OnlineSecurity\").setOutputCol(\"OnlineSecurity_Int\").fit(df)\n","onlineBackupIndexer = StringIndexer().setInputCol(\"OnlineBackup\").setOutputCol(\"OnlineBackup_Int\").fit(df)\n","deviceIndexer = StringIndexer().setInputCol(\"DeviceProtection\").setOutputCol(\"DeviceProtection_Int\").fit(df)\n","techIndexer = StringIndexer().setInputCol(\"TechSupport\").setOutputCol(\"TechSupport_Int\").fit(df)\n","streamingTVIndexer = StringIndexer().setInputCol(\"StreamingTV\").setOutputCol(\"StreamingTV_Int\").fit(df)\n","streamingMoviesIndexer = StringIndexer().setInputCol(\"StreamingMovies\").setOutputCol(\"StreamingMovies_Int\").fit(df)\n","contractIndexer = StringIndexer().setInputCol(\"Contract\").setOutputCol(\"Contract_Int\").fit(df)\n","paperlessIndexer = StringIndexer().setInputCol(\"PaperlessBilling\").setOutputCol(\"PaperlessBilling_Int\").fit(df)\n","paymentIndexer = StringIndexer().setInputCol(\"PaymentMethod\").setOutputCol(\"PaymentMethod_Int\").fit(df)\n","monthlyIndexer = StringIndexer().setInputCol(\"MonthlyCharges\").setOutputCol(\"MonthlyCharges_Int\").fit(df)\n","totalIndexer = StringIndexer().setInputCol(\"TotalCharges\").setOutputCol(\"TotalCharges_Int\").fit(df)"]},{"cell_type":"code","execution_count":150,"metadata":{},"outputs":[{"output_type":"stream","name":"stdout","text":["CustomerID\nSeniorCitizen\nPartner\nDependents\nTenure\nPhoneService\nMultipleLines\nInternetService\nOnlineSecurity\nOnlineBackup\nDeviceProtection\nTechSupport\nStreamingTV\nStreamingMovies\nContract\nPaperlessBilling\nPaymentMethod\nMonthlyCharges\nTotalCharges\n['SeniorCitizen_Int', 'Partner_Int', 'Dependents_Int', 'Tenure', 'PhoneService_Int', 'MultipleLines_Int', 'InternetService_Int', 'OnlineSecurity_Int', 'OnlineBackup_Int', 'DeviceProtection_Int', 'TechSupport_Int', 'StreamingTV_Int', 'StreamingMovies_Int', 'PaperlessBilling_Int', 'PaymentMethod_Int', 'MonthlyCharges', 'TotalCharges', 'Gender_Int']\n"]}],"source":["featureCols = df.columns.copy()\n","for col in featureCols:\n","    print(col)\n","    if not col == \"Tenure\" and not col == \"MonthlyCharges\" and not col == \"TotalCharges\":\n","        featureCols.remove(col)\n","        colname = col +\"_Int\"\n","        featureCols = featureCols + [colname]\n","    else:\n","        featureCols.remove(col)\n","        featureCols = featureCols + [col]\n","\n","featureCols.remove(\"Contract_Int\")\n","featureCols.remove(\"CustomerID_Int\")\n","featureCols.remove(\"Gender\")\n","featureCols = featureCols + [\"Gender_Int\"]\n","print(featureCols)\n"]},{"cell_type":"code","execution_count":151,"metadata":{},"outputs":[],"source":["assembler =  VectorAssembler(outputCol=\"features\", inputCols=list(featureCols), handleInvalid=\"keep\")"]},{"cell_type":"code","execution_count":152,"metadata":{},"outputs":[],"source":["featureIndexer = VectorIndexer(inputCol=\"features\",outputCol=\"indexedFeatures\", maxCategories=6, handleInvalid=\"keep\") "]},{"cell_type":"code","execution_count":153,"metadata":{},"outputs":[],"source":["predConverter = IndexToString(inputCol=\"prediction\",outputCol=\"predictedLabel\",labels=contractIndexer.labels)"]},{"source":["## Decision Tree"],"cell_type":"markdown","metadata":{}},{"cell_type":"code","execution_count":154,"metadata":{},"outputs":[],"source":["# dt = DecisionTreeClassifier(labelCol=\"Contract_Int\", featuresCol=\"features\")\n","# paramGrid = ParamGridBuilder().addGrid(dt.maxDepth, [ 10, 15 , 20 ]) \\\n","# \t\t\t\t              .addGrid(dt.minInfoGain, [ 0.02, 0.01, 0.001]) \\\n","# \t\t\t\t              .addGrid(dt.minInstancesPerNode, [5, 10, 15]) \\\n","#                               .addGrid(dt.maxBins, [5, 6, 9]) \\\n","# \t\t\t\t              .build()\n"]},{"source":["## Random Forest"],"cell_type":"markdown","metadata":{}},{"cell_type":"code","execution_count":155,"metadata":{},"outputs":[],"source":["new_df = df.select(\"Contract\")\n"]},{"cell_type":"code","execution_count":406,"metadata":{},"outputs":[],"source":["dt = RandomForestClassifier(labelCol=\"Contract_Int\", featuresCol=\"features\", seed=12345)\n","paramGrid = ParamGridBuilder().addGrid(dt.subsamplingRate, [ 1 ]) \\\n","                .addGrid(dt.featureSubsetStrategy, [ 'sqrt' ]) \\\n","                .addGrid(dt.numTrees, [50]) \\\n","                .addGrid(dt.minInstancesPerNode, [10]) \\\n","                .build()\n","\t\t\t\t\t\t\t  \n","\n","                            #   \n","\t\t\t\t            #   \n","                            #   \n","                            #   \n","\t\t\t\t              \n","\t\t\t\t              \n","#minInstancesPerNode=1350, featureSubsetStrategy='sqrt', subsamplingRate=1, seed= 12345, numTrees=850)"]},{"source":["### SVM -> geht nicht (Da nur 2 Klassen)"],"cell_type":"markdown","metadata":{}},{"cell_type":"code","execution_count":407,"metadata":{},"outputs":[],"source":["# lsvc = LinearSVC(labelCol=\"Contract_Int\",aggregationDepth=2, featuresCol=\"features\" ) \n","# #lsvc = LinearSVC(aggregationDepth=2) \n","# paramGrid = ParamGridBuilder().addGrid(lsvc.maxIter, [100])\\\n","#                                  .addGrid(lsvc.regParam, [0.1, 0.001, 0.0001]) \\\n","#                                  .addGrid(lsvc.standardization, [True, False]) \\\n","#                                  .build()\n","# dt = OneVsRest(classifier=lsvc, labelCol=\"Contract_Int\", featuresCol=\"features\", rawPredictionCol=\"rawPrediction\")"]},{"source":["## Logistic Regression"],"cell_type":"markdown","metadata":{}},{"cell_type":"code","execution_count":408,"metadata":{},"outputs":[],"source":["# dt = LogisticRegression(featuresCol=\"features\", labelCol=\"Contract_Int\")\n","# paramGrid = ParamGridBuilder().addGrid(dt.maxIter, [100, 120 , 150])\\\n","#                                  .addGrid(dt.regParam, [0.1, 0.3, 0.5]) \\\n","#                                  .addGrid(dt.standardization, [True, False]) \\\n","#                                  .addGrid(dt.elasticNetParam, [0, 1]) \\\n","#                                  .build()"]},{"source":["## Linear Regression"],"cell_type":"markdown","metadata":{}},{"cell_type":"code","execution_count":409,"metadata":{},"outputs":[],"source":["# lr = LinearRegression(featuresCol=\"features\", labelCol=\"Contract_Int\")\n","# paramGrid = ParamGridBuilder().addGrid(lr.maxIter, [100, 120 , 150])\\\n","#                                  .addGrid(lr.regParam, [0.1, 0.3, 0.5]) \\\n","#                                  .addGrid(lr.standardization, [True, False]) \\\n","#                                  .addGrid(lr.elasticNetParam, [0, 1]) \\\n","#                                  .build()\n","# dt = OneVsRest(classifier=lr, labelCol=\"Contract_Int\", featuresCol=\"features\", rawPredictionCol=\"rawPrediction\")"]},{"cell_type":"code","execution_count":410,"metadata":{},"outputs":[],"source":["splits = df.randomSplit([0.9, 0.1 ], 12345)\n","train = splits[0]\n","test = splits[1]"]},{"cell_type":"code","execution_count":411,"metadata":{},"outputs":[],"source":["pipeline = Pipeline(stages= [genderIndexer, seniorIndexer, partnerIndexer,\n","\t\t\t\tDependentsIndexer, phoneIndexer, multipleIndexer, internetIndexer, onlineSecurityIndexer, onlineBackupIndexer, deviceIndexer, techIndexer, streamingTVIndexer, streamingMoviesIndexer, contractIndexer, paperlessIndexer, paymentIndexer, assembler, featureIndexer,  dt, predConverter])"]},{"cell_type":"code","execution_count":412,"metadata":{},"outputs":[],"source":["#evaluator =  BinaryClassificationEvaluator(labelCol=\"Contract_Int\", rawPredictionCol=\"rawPrediction\", metricName=\"areaUnderROC\")\n","evaluator =  MulticlassClassificationEvaluator(labelCol=\"Contract_Int\", metricName=\"f1\")"]},{"cell_type":"code","execution_count":413,"metadata":{},"outputs":[],"source":["cv = CrossValidator(estimator=pipeline,evaluator=evaluator,estimatorParamMaps=paramGrid,numFolds=2, parallelism=2)"]},{"cell_type":"code","execution_count":414,"metadata":{},"outputs":[],"source":["cvModel = cv.fit(train)"]},{"cell_type":"code","execution_count":415,"metadata":{},"outputs":[{"output_type":"stream","name":"stdout","text":["Learned classification tree model:\n StringIndexerModel: uid=StringIndexer_d6b1f9a42f13, handleInvalid=error\nBest Params: \n handleInvalid: how to handle invalid data (unseen or NULL values) in features and label column of string type. Options are 'skip' (filter out rows with invalid data), error (throw an error), or 'keep' (put invalid data in a special additional bucket, at index numLabels). (default: error)\ninputCol: input column name. (current: OnlineSecurity)\ninputCols: input column names. (undefined)\noutputCol: output column name. (default: StringIndexer_d6b1f9a42f13__output, current: OnlineSecurity_Int)\noutputCols: output column names. (undefined)\nstringOrderType: How to order labels of string column. The first label after ordering is assigned an index of 0. Supported options: frequencyDesc, frequencyAsc, alphabetDesc, alphabetAsc. Default is frequencyDesc. In case of equal frequency when under frequencyDesc/Asc, the strings are further sorted alphabetically (default: frequencyDesc)\n"]}],"source":["treeModel = cvModel.bestModel.stages[7]\n","print(\"Learned classification tree model:\\n\",treeModel)\n","print(\"Best Params: \\n\", treeModel.explainParams())"]},{"cell_type":"code","execution_count":416,"metadata":{},"outputs":[{"output_type":"stream","name":"stdout","text":["+----------+------------+--------------+--------------+--------------------+\n|prediction|Contract_Int|predictedLabel|      Contract|            features|\n+----------+------------+--------------+--------------+--------------------+\n|       1.0|         2.0|      Two year|      One year|[0.0,1.0,1.0,55.0...|\n|       1.0|         1.0|      Two year|      Two year|[0.0,1.0,1.0,54.0...|\n|       0.0|         2.0|Month-to-month|      One year|[0.0,0.0,0.0,27.0...|\n|       0.0|         0.0|Month-to-month|Month-to-month|(18,[1,3,5,6,13,1...|\n|       1.0|         2.0|      Two year|      One year|(18,[0,1,3,5,8,9,...|\n|       0.0|         0.0|Month-to-month|Month-to-month|(18,[1,2,3,5,8,11...|\n|       0.0|         0.0|Month-to-month|Month-to-month|(18,[0,1,3,11,12,...|\n|       0.0|         1.0|Month-to-month|      Two year|[0.0,0.0,1.0,25.0...|\n|       0.0|         0.0|Month-to-month|Month-to-month|[1.0,0.0,0.0,52.0...|\n|       0.0|         0.0|Month-to-month|Month-to-month|(18,[0,3,6,15,16,...|\n|       0.0|         2.0|Month-to-month|      One year|[0.0,1.0,1.0,48.0...|\n|       0.0|         0.0|Month-to-month|Month-to-month|[0.0,0.0,0.0,9.0,...|\n|       0.0|         0.0|Month-to-month|Month-to-month|(18,[3,8,10,11,12...|\n|       1.0|         1.0|      Two year|      Two year|[0.0,1.0,0.0,65.0...|\n|       0.0|         0.0|Month-to-month|Month-to-month|(18,[3,6,13,15,16...|\n|       0.0|         2.0|Month-to-month|      One year|[0.0,0.0,0.0,40.0...|\n|       1.0|         1.0|      Two year|      Two year|[0.0,1.0,1.0,46.0...|\n|       1.0|         2.0|      Two year|      One year|(18,[3,8,9,10,12,...|\n|       0.0|         0.0|Month-to-month|Month-to-month|(18,[3,9,10,11,12...|\n|       0.0|         0.0|Month-to-month|Month-to-month|(18,[3,15,16,17],...|\n+----------+------------+--------------+--------------+--------------------+\nonly showing top 20 rows\n\n"]}],"source":["predictions = cvModel.transform(test)\n","predictions.select(\"prediction\", \"Contract_Int\", \"predictedLabel\", \"Contract\", \"features\").show()"]},{"cell_type":"code","execution_count":417,"metadata":{},"outputs":[{"output_type":"stream","name":"stdout","text":["+----------+-----+\n","|prediction|count|\n","+----------+-----+\n","|       0.0|  398|\n","|       1.0|  187|\n","|       2.0|   40|\n","+----------+-----+\n","\n","+--------------+-----+\n","|      Contract|count|\n","+--------------+-----+\n","|Month-to-month| 3244|\n","|      One year| 1214|\n","|      Two year| 1407|\n","+--------------+-----+\n","\n"]}],"source":["new_df = predictions.groupBy(\"prediction\").count()\n","new_df.show()\n","new_train_df = train.groupBy(\"Contract\").count()\n","new_train_df.show()"]},{"cell_type":"code","execution_count":418,"metadata":{},"outputs":[{"output_type":"stream","name":"stdout","text":["Test Error =  0.35554222750285813\n"]}],"source":["accuracy = evaluator.evaluate(predictions)\n","print(\"Test Error = \" ,(1.0 - accuracy))"]},{"cell_type":"code","execution_count":419,"metadata":{},"outputs":[],"source":["predictionAndLabels = predictions.select(\"prediction\", \"Contract_Int\").rdd.map(lambda p: [p[0], p[1]]) # Map to RDD prediction|label\n","metrics =  MulticlassMetrics(predictionAndLabels)"]},{"cell_type":"code","execution_count":420,"metadata":{},"outputs":[{"output_type":"stream","name":"stdout","text":["Confusion matrix: \n DenseMatrix([[305.,  11.,  16.],\n             [ 21., 118.,  11.],\n             [ 72.,  58.,  13.]])\n"]}],"source":["confusion = metrics.confusionMatrix()\n","print(\"Confusion matrix: \\n\" , confusion)"]},{"cell_type":"code","execution_count":421,"metadata":{},"outputs":[{"output_type":"stream","name":"stdout","text":["Class 2.000000 precision = 0.325000\n\nClass 2.000000 recall = 0.090909\n\nClass 2.000000 F1 score = 0.142077\n\nClass 1.000000 precision = 0.631016\n\nClass 1.000000 recall = 0.786667\n\nClass 1.000000 F1 score = 0.700297\n\nClass 0.000000 precision = 0.766332\n\nClass 0.000000 recall = 0.918675\n\nClass 0.000000 F1 score = 0.835616\n\n"]}],"source":["labels = predictionAndLabels.map(lambda x: x[1]).distinct().collect()\n","for label in  labels:\n","  print(\"Class %f precision = %f\\n\" % (label , metrics.precision(label)))\n","  print(\"Class %f recall = %f\\n\" % (label, metrics.recall(label)))\n","  print(\"Class %f F1 score = %f\\n\" % (label, metrics.fMeasure( label)))\n"]},{"cell_type":"code","execution_count":422,"metadata":{},"outputs":[{"output_type":"stream","name":"stdout","text":["Weighted precision = 0.6328792271518018\n\nWeighted recall = 0.6976\n\nWeighted F1 score = <bound method MulticlassMetrics.weightedFMeasure of <pyspark.mllib.evaluation.MulticlassMetrics object at 0x7f32f8382ad0>>\n\nWeighted false positive rate = 0.2162858987498202\n\n"]}],"source":["print(\"Weighted precision = %s\\n\" % metrics.weightedPrecision)\n","print(\"Weighted recall = %s\\n\" % metrics.weightedRecall)\n","print(\"Weighted F1 score = %s\\n\" % metrics.weightedFMeasure)\n","print(\"Weighted false positive rate = %s\\n\" % metrics.weightedFalsePositiveRate)"]},{"cell_type":"code","execution_count":423,"metadata":{},"outputs":[{"output_type":"stream","name":"stdout","text":["Recall = 0.7866666666666666\nPrecision = 0.6310160427807486\nAccuracy = 0.6976\nF1 = 0.7002967359050445\n"]}],"source":["print(\"Recall = %s\" % metrics.recall(1.0))\n","print(\"Precision = %s\" % metrics.precision(1.0))\n","print(\"Accuracy = %s\" % metrics.accuracy) \n","print(\"F1 = %s\" % metrics.fMeasure(1.0))"]},{"cell_type":"code","execution_count":424,"metadata":{},"outputs":[],"source":["#spark.stop()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"venv","language":"python","name":"venv"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.5-final"}},"nbformat":4,"nbformat_minor":2}