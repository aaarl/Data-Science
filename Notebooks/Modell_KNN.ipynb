{"cells":[{"cell_type":"markdown","metadata":{},"source":["# KÃ¼nstliches neuronales Netz"]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[],"source":["from pyspark.sql.types import BooleanType\n","from pyspark.ml.feature import IndexToString, Normalizer, StringIndexer, VectorAssembler, VectorIndexer, StandardScaler\n","from pyspark.ml.classification import MultilayerPerceptronClassifier\n","from pyspark.sql.session import SparkSession\n","from pyspark.sql.functions import expr\n","from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n","from helpers.helper_functions import translate_to_file_string\n","from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n","from pyspark.ml import Pipeline\n","from pyspark.mllib.evaluation import MulticlassMetrics\n","from pyspark.mllib.util import MLUtils\n","import pandas as pd\n","from IPython.display import display, HTML\n","\n","#Change Column Names\n","def delete_space(df):\n","    names = df.schema.names\n","    for name in names:\n","        newName = name.replace(\" \",\"\")\n","        df = df.withColumnRenamed(name, newName)\n","    return df"]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[],"source":["inputFile = translate_to_file_string(\"../data/data.csv\")"]},{"cell_type":"markdown","metadata":{},"source":["Spark session creation "]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[],"source":["spark = (SparkSession\n","       .builder\n","       .appName(\"Modell_KNN\")\n","       .getOrCreate())"]},{"cell_type":"markdown","metadata":{},"source":["DataFrame creation using an ifered Schema "]},{"cell_type":"code","execution_count":24,"metadata":{},"outputs":[],"source":["# create a DataFrame using an ifered Schema \n","df = spark.read.option(\"header\", \"true\") \\\n","       .option(\"inferSchema\", \"true\") \\\n","       .option(\"delimiter\", \";\") \\\n","       .csv(inputFile) \n","\n","df = delete_space(df)\n","df_orig = df\n","df = df.where(\"MonthlyCharges Between 22 AND 95\")\n","df = df.where(\"TotalCharges IS NOT NULL\")"]},{"source":["## Prepare training and test data."],"cell_type":"markdown","metadata":{}},{"source":["### Use this for Pandas Dataframe"],"cell_type":"markdown","metadata":{}},{"cell_type":"code","execution_count":25,"metadata":{},"outputs":[],"source":["# #Create Pandas DataFrame\n","# df_pandas = df.toPandas()\n","# df_pandas_cat = df.toPandas()\n","# #Pandas Indexing Method to Integer or Category Datatype\n","# pandasCol = list(df_pandas)\n","# for col in pandasCol:\n","#     if df_pandas[col].dtypes=='object':\n","#         if not col == \"Contract\":\n","#             #Categorize\n","#             df_pandas_cat[col]= pd.Categorical(pd.factorize(df_pandas_cat[col])[0])\n","#             #ToInteger\n","#             df_pandas[col]= pd.factorize(df_pandas[col])[0]\n","\n","# #Define whicht Columns should be normalized\n","# newCols = []\n","# for col in pandasCol:\n","#     if not col == \"Contract\":\n","#         newCols.append(col)\n","\n","# #Normalize the selected Columns\n","# df_pandas[newCols]=(df_pandas[newCols]-df_pandas[newCols].min())/(df_pandas[newCols].max()-df_pandas[newCols].min())\n","\n","# #Write Pandas Dataframe Back to Spark Dataframe\n","# df_temp = spark.createDataFrame(df_pandas)\n","# df = df_temp\n","# # Create Indexer for Contract (Still needed)\n","# contractIndexer = StringIndexer().setInputCol(\"Contract\").setOutputCol(\"Contract_Int\").fit(df)\n","\n","# #Create FeatureCols \n","# featureCols = df.columns.copy()\n","# featureCols.remove(\"Contract\")\n","# featureCols.remove(\"CustomerID\")"]},{"source":["### Create Indexer"],"cell_type":"markdown","metadata":{}},{"cell_type":"code","execution_count":26,"metadata":{},"outputs":[],"source":["#Comment the Following if Pandas-Dataset is used\n","IDIndexer = StringIndexer().setInputCol(\"CustomerID\").setOutputCol(\"CustomerID_Int\").fit(df)\n","genderIndexer = StringIndexer().setInputCol(\"Gender\").setOutputCol(\"Gender_Int\").fit(df)\n","seniorIndexer = StringIndexer().setInputCol(\"SeniorCitizen\").setOutputCol(\"SeniorCitizen_Int\").fit(df)\n","partnerIndexer = StringIndexer().setInputCol(\"Partner\").setOutputCol(\"Partner_Int\").fit(df)\n","DependentsIndexer = StringIndexer().setInputCol(\"Dependents\").setOutputCol(\"Dependents_Int\").fit(df)\n","tenureIndexer = StringIndexer().setInputCol(\"Tenure\").setOutputCol(\"Tenure_Int\").fit(df)\n","phoneIndexer = StringIndexer().setInputCol(\"PhoneService\").setOutputCol(\"PhoneService_Int\").fit(df)\n","multipleIndexer = StringIndexer().setInputCol(\"MultipleLines\").setOutputCol(\"MultipleLines_Int\").fit(df)\n","internetIndexer = StringIndexer().setInputCol(\"InternetService\").setOutputCol(\"InternetService_Int\").fit(df)\n","onlineSecurityIndexer = StringIndexer().setInputCol(\"OnlineSecurity\").setOutputCol(\"OnlineSecurity_Int\").fit(df)\n","onlineBackupIndexer = StringIndexer().setInputCol(\"OnlineBackup\").setOutputCol(\"OnlineBackup_Int\").fit(df)\n","deviceIndexer = StringIndexer().setInputCol(\"DeviceProtection\").setOutputCol(\"DeviceProtection_Int\").fit(df)\n","techIndexer = StringIndexer().setInputCol(\"TechSupport\").setOutputCol(\"TechSupport_Int\").fit(df)\n","streamingTVIndexer = StringIndexer().setInputCol(\"StreamingTV\").setOutputCol(\"StreamingTV_Int\").fit(df)\n","streamingMoviesIndexer = StringIndexer().setInputCol(\"StreamingMovies\").setOutputCol(\"StreamingMovies_Int\").fit(df)\n","contractIndexer = StringIndexer().setInputCol(\"Contract\").setOutputCol(\"Contract_Int\").fit(df)\n","paperlessIndexer = StringIndexer().setInputCol(\"PaperlessBilling\").setOutputCol(\"PaperlessBilling_Int\").fit(df)\n","paymentIndexer = StringIndexer().setInputCol(\"PaymentMethod\").setOutputCol(\"PaymentMethod_Int\").fit(df)\n","monthlyIndexer = StringIndexer().setInputCol(\"MonthlyCharges\").setOutputCol(\"MonthlyCharges_Int\").fit(df)\n","totalIndexer = StringIndexer().setInputCol(\"TotalCharges\").setOutputCol(\"TotalCharges_Int\").fit(df)"]},{"source":["### Identify the Columns that should be used for the Feature Vector"],"cell_type":"markdown","metadata":{}},{"cell_type":"code","execution_count":27,"metadata":{},"outputs":[],"source":["##Comment this if Pandas Dataset is used\n","featureCols = df.columns.copy()\n","for col in featureCols:\n","    if not col == \"Tenure\" and not col == \"MonthlyCharges\" and not col == \"TotalCharges\":\n","        featureCols.remove(col)\n","        colname = col +\"_Int\"\n","        featureCols = featureCols + [colname]\n","    else:\n","        featureCols.remove(col)\n","        featureCols = featureCols + [col]\n","\n","featureCols.remove(\"Contract_Int\")\n","featureCols.remove(\"CustomerID_Int\")\n","featureCols.remove(\"Gender\")\n","featureCols = featureCols + [\"Gender_Int\"]"]},{"source":["### Create Assembler, FeatureIndexer, PredConverter and Scaler"],"cell_type":"markdown","metadata":{}},{"cell_type":"code","execution_count":28,"metadata":{},"outputs":[],"source":["assembler =  VectorAssembler(outputCol=\"features\", inputCols=list(featureCols))\n","\n","featureIndexer = VectorIndexer(inputCol=\"features\",outputCol=\"indexedFeatures\", maxCategories=6)\n"," \n","predConverter = IndexToString(inputCol=\"prediction\",outputCol=\"predictedLabel\",labels=contractIndexer.labels)\n","\n","scaler = StandardScaler(inputCol=\"indexedFeatures\", outputCol=\"scaledFeatures\",withStd=True, withMean=False)"]},{"source":["### Build the KNN"],"cell_type":"markdown","metadata":{}},{"cell_type":"code","execution_count":29,"metadata":{},"outputs":[],"source":["# input layer of size 18 (features), two intermediate of size 128, 20 and 5 and output of size 3 (classes)\n","\n","knn = MultilayerPerceptronClassifier(featuresCol=\"scaledFeatures\", labelCol=\"Contract_Int\")   \n","paramGrid =  ParamGridBuilder().addGrid(knn.layers, [[ 18, 128, 20, 5, 3 ]]) \\\n","\t\t\t\t.addGrid(knn.blockSize,  [128 ]) \\\n","                .addGrid(knn.maxIter,[ 500 ]) \\\n","\t\t\t\t.addGrid(knn.tol, [ 0.05 ]) \\\n","\t\t\t\t.build()"]},{"source":["### Create Train and Test Datasets"],"cell_type":"markdown","metadata":{}},{"cell_type":"code","execution_count":30,"metadata":{},"outputs":[],"source":["splits = df.randomSplit([0.9, 0.1 ], 12345)\n","train = splits[0]\n","test = splits[1]"]},{"source":["### Build the Pipeline"],"cell_type":"markdown","metadata":{}},{"cell_type":"code","execution_count":31,"metadata":{},"outputs":[],"source":["#Use This for Pandas-Dataframe\n","# pipeline = Pipeline(stages= [contractIndexer, assembler, featureIndexer, scaler, knn, predConverter])"]},{"cell_type":"code","execution_count":32,"metadata":{},"outputs":[],"source":["#Use This for Spark Dataframe\n","pipeline = Pipeline(stages= [genderIndexer, seniorIndexer, partnerIndexer, DependentsIndexer, phoneIndexer, multipleIndexer, internetIndexer, onlineSecurityIndexer, onlineBackupIndexer, deviceIndexer, techIndexer, streamingTVIndexer, streamingMoviesIndexer, contractIndexer, paperlessIndexer, paymentIndexer, assembler, featureIndexer, scaler, knn, predConverter])"]},{"source":["### Build Evaluator and CrossValidator and train the Model"],"cell_type":"markdown","metadata":{}},{"cell_type":"code","execution_count":33,"metadata":{},"outputs":[],"source":["evaluator =  MulticlassClassificationEvaluator(labelCol=\"Contract_Int\", metricName=\"f1\")\n","\n","cv = CrossValidator(estimator=pipeline,evaluator=evaluator,estimatorParamMaps=paramGrid,numFolds=10, parallelism=2)\n","\n","cvModel = cv.fit(train)"]},{"cell_type":"code","execution_count":34,"metadata":{},"outputs":[{"output_type":"stream","name":"stdout","text":["Learned classification Random Forest model:\n MultilayerPerceptronClassificationModel: uid=MultilayerPerceptronClassifier_687d54a847e9, numLayers=5, numClasses=3, numFeatures=18\nBest Params: \n blockSize: block size for stacking input data in matrices. Data is stacked within partitions. If block size is more than remaining data in a partition then it is adjusted to the size of this data. (default: 128, current: 128)\nfeaturesCol: features column name. (default: features, current: scaledFeatures)\ninitialWeights: The initial weights of the model. (undefined)\nlabelCol: label column name. (default: label, current: Contract_Int)\nlayers: Sizes of layers from input layer to output layer E.g., Array(780, 100, 10) means 780 inputs, one hidden layer with 100 neurons and output layer of 10 neurons. (current: [18, 128, 20, 5, 3])\nmaxIter: max number of iterations (>= 0). (default: 100, current: 500)\npredictionCol: prediction column name. (default: prediction)\nprobabilityCol: Column name for predicted class conditional probabilities. Note: Not all models output well-calibrated probability estimates! These probabilities should be treated as confidences, not precise probabilities. (default: probability)\nrawPredictionCol: raw prediction (a.k.a. confidence) column name. (default: rawPrediction)\nseed: random seed. (default: -790466004025719482)\nsolver: The solver algorithm for optimization. Supported options: l-bfgs, gd. (default: l-bfgs)\nstepSize: Step size to be used for each iteration of optimization (>= 0). (default: 0.03)\nthresholds: Thresholds in multi-class classification to adjust the probability of predicting each class. Array must have length equal to the number of classes, with values > 0, excepting that at most one value may be 0. The class with largest value p/t is predicted, where p is the original probability of that class and t is the class's threshold. (undefined)\ntol: the convergence tolerance for iterative algorithms (>= 0). (default: 1e-06, current: 0.05)\n"]}],"source":["#stages[19] for Spark Dataframe ;  stages[4] for Pandas Dataframe \n","knnModel = cvModel.bestModel.stages[19]\n","print(\"Learned classification Random Forest model:\\n\",knnModel)\n","print(\"Best Params: \\n\", knnModel.explainParams())"]},{"cell_type":"code","execution_count":35,"metadata":{},"outputs":[{"output_type":"stream","name":"stdout","text":["+----------+------------+--------------+--------------+--------------------+--------------------+\n|prediction|Contract_Int|predictedLabel|      Contract|            features|      scaledFeatures|\n+----------+------------+--------------+--------------+--------------------+--------------------+\n|       0.0|         2.0|Month-to-month|      One year|[0.0,0.0,0.0,27.0...|[0.0,0.0,0.0,1.11...|\n|       0.0|         1.0|Month-to-month|      Two year|[0.0,1.0,1.0,25.0...|[0.0,2.0066441334...|\n|       0.0|         0.0|Month-to-month|Month-to-month|(18,[3,5,8,9,12,1...|(18,[3,5,8,9,12,1...|\n|       0.0|         0.0|Month-to-month|Month-to-month|(18,[1,3,6,9,11,1...|(18,[1,3,6,9,11,1...|\n|       0.0|         2.0|Month-to-month|      One year|[1.0,0.0,0.0,44.0...|[2.66845817562711...|\n|       0.0|         1.0|Month-to-month|      Two year|[0.0,1.0,1.0,48.0...|[0.0,2.0066441334...|\n|       0.0|         0.0|Month-to-month|Month-to-month|(18,[1,2,3,6,12,1...|(18,[1,2,3,6,12,1...|\n|       0.0|         0.0|Month-to-month|Month-to-month|(18,[3,6,8,9,12,1...|(18,[3,6,8,9,12,1...|\n|       0.0|         0.0|Month-to-month|Month-to-month|(18,[3,6,11,12,14...|(18,[3,6,11,12,14...|\n|       0.0|         0.0|Month-to-month|Month-to-month|(18,[1,3,6,11,15,...|(18,[1,3,6,11,15,...|\n|       0.0|         0.0|Month-to-month|Month-to-month|(18,[1,3,6,13,15,...|(18,[1,3,6,13,15,...|\n|       0.0|         0.0|Month-to-month|Month-to-month|[0.0,1.0,0.0,48.0...|[0.0,2.0066441334...|\n|       0.0|         0.0|Month-to-month|Month-to-month|(18,[3,6,12,15,16...|(18,[3,6,12,15,16...|\n|       0.0|         0.0|Month-to-month|Month-to-month|(18,[3,7,8,9,13,1...|(18,[3,7,8,9,13,1...|\n|       0.0|         1.0|Month-to-month|      Two year|[0.0,1.0,1.0,69.0...|[0.0,2.0066441334...|\n|       0.0|         0.0|Month-to-month|Month-to-month|(18,[1,3,4,5,11,1...|(18,[1,3,4,5,11,1...|\n|       0.0|         0.0|Month-to-month|Month-to-month|(18,[2,3,7,11,12,...|(18,[2,3,7,11,12,...|\n|       0.0|         0.0|Month-to-month|Month-to-month|(18,[3,6,9,11,15,...|(18,[3,6,9,11,15,...|\n|       0.0|         2.0|Month-to-month|      One year|(18,[0,3,4,5,12,1...|(18,[0,3,4,5,12,1...|\n|       0.0|         2.0|Month-to-month|      One year|(18,[3,6,7,9,11,1...|(18,[3,6,7,9,11,1...|\n+----------+------------+--------------+--------------+--------------------+--------------------+\nonly showing top 20 rows\n\n"]}],"source":["predictions = cvModel.transform(test)\n","predictions.select(\"prediction\", \"Contract_Int\", \"predictedLabel\", \"Contract\", \"features\", \"scaledFeatures\").show()"]},{"source":["### Evaluation"],"cell_type":"markdown","metadata":{}},{"cell_type":"code","execution_count":36,"metadata":{},"outputs":[],"source":["predictionAndLabels = predictions.select(\"prediction\", \"Contract_Int\").rdd.map(lambda p: [p[0], p[1]]) # Map to RDD prediction|label\n","metrics =  MulticlassMetrics(predictionAndLabels)"]},{"cell_type":"code","execution_count":37,"metadata":{},"outputs":[{"output_type":"stream","name":"stdout","text":["Confusion matrix: \n DenseMatrix([[236.,   0.,   0.],\n             [ 73.,   0.,   0.],\n             [ 83.,   0.,   0.]])\n"]}],"source":["#Confusion Matrix\n","confusion = metrics.confusionMatrix()\n","print(\"Confusion matrix: \\n\" , confusion)"]},{"cell_type":"code","execution_count":38,"metadata":{},"outputs":[{"output_type":"stream","name":"stdout","text":["Class 2.000000 precision = 0.000000\n\nClass 2.000000 recall = 0.000000\n\nClass 2.000000 F1 score = 0.000000\n\nClass 1.000000 precision = 0.000000\n\nClass 1.000000 recall = 0.000000\n\nClass 1.000000 F1 score = 0.000000\n\nClass 0.000000 precision = 0.602041\n\nClass 0.000000 recall = 1.000000\n\nClass 0.000000 F1 score = 0.751592\n\n"]}],"source":["#Key Figures per class\n","labels = predictionAndLabels.map(lambda x: x[1]).distinct().collect()\n","for label in  labels:\n","  print(\"Class %f precision = %f\\n\" % (label , metrics.precision(label)))\n","  print(\"Class %f recall = %f\\n\" % (label, metrics.recall(label)))\n","  print(\"Class %f F1 score = %f\\n\" % (label, metrics.fMeasure( label)))\n"]},{"cell_type":"code","execution_count":39,"metadata":{},"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy = 0.6020408163265306\n\nTest Error = 0.3979591836734694\n\nWeighted precision = 0.3624531445231154\n\nWeighted recall = 0.6020408163265306\n\nWeighted F1 score = 0.45248927596516314\n\n"]}],"source":["#Model Key Figures \n","print(\"Accuracy = %s\\n\" % metrics.accuracy) \n","print(\"Test Error = %s\\n\" % (1 - metrics.accuracy))\n","print(\"Weighted precision = %s\\n\" % metrics.weightedPrecision)\n","print(\"Weighted recall = %s\\n\" % metrics.weightedRecall)\n","print(\"Weighted F1 score = %s\\n\" % metrics.weightedFMeasure())"]},{"cell_type":"code","execution_count":40,"metadata":{},"outputs":[],"source":["spark.stop()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"venv","language":"python","name":"venv"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.5-final"}},"nbformat":4,"nbformat_minor":2}